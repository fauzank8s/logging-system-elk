input {
  file {
    mode => "read"
    path => "/usr/share/logstash/ingest_data/*.log"
    exit_after_read => true
    file_completed_action => "log"
    file_completed_log_path => "/usr/share/logstash/ingest_data/logstash_completed.log"
  }
}

filter {
  # Parse the log line using grok
  grok {
    match => {
      "message" => "%{TIMESTAMP_ISO8601:timestamp} %{WORD:service} %{NUMBER:status_code} %{NUMBER:response_time}ms %{WORD:user_id} %{WORD:transaction_id} %{GREEDYDATA:additional_info}"
    }
  }

  # Convert data types
  mutate {
    convert => {
      "status_code" => "integer"
      "response_time" => "integer"
    }
  }

  # Add error flag and category for status codes >= 400
  if [status_code] >= 400 {
    mutate {
      add_field => {
        "is_error" => true
        "error_category" => "%{[status_code]}"
      }
    }
  } else {
    mutate {
      add_field => {
        "is_error" => false
      }
    }
  }

  # Parse timestamp
  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss" ]
    target => "@timestamp"
  }

  # Generate per-service metrics
  aggregate {
    task_id => "%{service}"
    code => "
      # Initialize counters
      map['total_requests'] ||= 0
      map['error_count'] ||= 0
      map['total_response_time'] ||= 0
      
      # Update metrics
      map['total_requests'] += 1
      map['error_count'] += 1 if event.get('is_error')
      map['total_response_time'] += event.get('response_time')
      
      # Calculate averages and rates
      map['error_rate'] = (map['error_count'].to_f / map['total_requests'] * 100).round(2)
      map['avg_response_time'] = (map['total_response_time'].to_f / map['total_requests']).round(2)
      
      # Add metrics to event
      event.set('service_total_requests', map['total_requests'])
      event.set('service_error_count', map['error_count'])
      event.set('service_error_rate', map['error_rate'])
      event.set('service_avg_response_time', map['avg_response_time'])
    "
    push_previous_map_as_event => true
    timeout => 5
  }
}

output {
  # Output individual log entries
  if ![service_total_requests] {
    elasticsearch {
      index => "logs-%{+YYYY.MM.dd}"
      hosts => "${ELASTIC_HOSTS}"
      user => "${ELASTIC_USER}"
      password => "${ELASTIC_PASSWORD}"
      cacert => "certs/ca/ca.crt"
    }
  }
  
  # Output aggregated metrics
  if [service_total_requests] {
    elasticsearch {
      index => "metrics-%{+YYYY.MM.dd}"
      hosts => "${ELASTIC_HOSTS}"
      user => "${ELASTIC_USER}"
      password => "${ELASTIC_PASSWORD}"
      cacert => "certs/ca/ca.crt"
    }
  }
}